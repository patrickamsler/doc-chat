{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:50:56.475743Z",
     "start_time": "2025-04-06T18:50:55.426977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from doc_chat.rag.document_loader import DocumentLoader\n",
    "from doc_chat.rag.vector_store import VectorStore\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ],
   "id": "82d9bd9c8ff121ec",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:51:32.511426Z",
     "start_time": "2025-04-06T18:50:56.485648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"../data/pdf/The Hundred-Page Machine Learning Book.pdf\"\n",
    "doc_loader = DocumentLoader(file_path)\n",
    "documents, splits = doc_loader.load_and_split()\n",
    "print(\"Number of documents: \" + str(len(documents)))\n",
    "print(\"Number of splits: \" + str(len(splits)))"
   ],
   "id": "3ab4e21534ad9deb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 152\n",
      "Number of splits: 385\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:51:32.577355Z",
     "start_time": "2025-04-06T18:51:32.574370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# document format\n",
    "documents[0]"
   ],
   "id": "2a891db20f76d3b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152, 'page': 0, 'page_label': '1'}, page_content='The\\nHundred-\\nPage\\nMachine\\nLearning\\nBook\\nAndriy Burkov')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:51:32.585265Z",
     "start_time": "2025-04-06T18:51:32.582986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print first 300 characters of the third page\n",
    "documents[2].page_content[:300]"
   ],
   "id": "70fe79e5cf5a314c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preface\\nLet’s start by telling the truth: machines don’t learn. What a typical “learning machine”\\ndoes, is ﬁnding a mathematical formula, which, when applied to a collection of inputs (called\\n“training data”), produces the desired outputs. This mathematical formula also generates the\\ncorrect outputs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:51:32.609509Z",
     "start_time": "2025-04-06T18:51:32.607130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split format\n",
    "splits[0]"
   ],
   "id": "63125bc673e1b99d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152, 'page': 0, 'page_label': '1'}, page_content='The\\nHundred-\\nPage\\nMachine\\nLearning\\nBook\\nAndriy Burkov')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:51:32.656253Z",
     "start_time": "2025-04-06T18:51:32.654142Z"
    }
   },
   "cell_type": "code",
   "source": "splits[2].page_content",
   "id": "1b6bafe36143cc5f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preface\\nLet’s start by telling the truth: machines don’t learn. What a typical “learning machine”\\ndoes, is ﬁnding a mathematical formula, which, when applied to a collection of inputs (called\\n“training data”), produces the desired outputs. This mathematical formula also generates the\\ncorrect outputs for most other inputs (distinct from the training data) on the condition that\\nthose inputs come from the same or a similar statistical distribution as the one the training\\ndata was drawn from.\\nWhy isn’t that learning? Because if you slightly distort the inputs, the output is very likely\\nto become completely wrong. It’s not how learning in animals works. If you learned to play\\na video game by looking straight at the screen, you would still be a good player if someone\\nrotates the screen slightly. A machine learning algorithm, if it was trained by “looking”\\nstraight at the screen, unless it was also trained to recognize rotation, will fail to play the\\ngame on a rotated screen.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:51:32.686586Z",
     "start_time": "2025-04-06T18:51:32.684177Z"
    }
   },
   "cell_type": "code",
   "source": "splits[3].page_content",
   "id": "97e6d7cfa59bfe48",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'straight at the screen, unless it was also trained to recognize rotation, will fail to play the\\ngame on a rotated screen.\\nSo why the name “machine learning” then? The reason, as is often the case, is marketing:\\nArthur Samuel, an American pioneer in the ﬁeld of computer gaming and artiﬁcial intelligence,\\ncoined the term in 1959 while at IBM. Similarly to how in the 2010s IBM tried to market\\nthe term “cognitive computing” to stand out from competition, in the 1960s, IBM used the\\nnew cool term “machine learning” to attract both clients and talented employees.\\nAs you can see, just like artiﬁcial intelligence is not intelligence, machine learning is not\\nlearning. However, machine learning is a universally recognized term that usually refers\\nto the science and engineering of building machines capable of doing various useful things\\nwithout being explicitly programmed to do so. So, the word “learning” in the term is used\\nby analogy with the learning in animals rather than literally.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:51:37.536541Z",
     "start_time": "2025-04-06T18:51:32.697366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# instantiate vector store\n",
    "vector_store = VectorStore(documents=splits, token=\"foo\")"
   ],
   "id": "4c2e0a6938202300",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:56:06.785444Z",
     "start_time": "2025-04-06T18:56:04.736015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answer = vector_store.qa_chain(\"Explain logistic regression?\", k=2)\n",
    "print(answer['result'])"
   ],
   "id": "5588f00f3ead90f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression is a classification learning algorithm that is used to predict the probability of a binary outcome. It is similar to linear regression in its mathematical formulation, but it is used for classification rather than regression. The goal of logistic regression is to optimize the values of x and b in order to interpret the output of f(x) as the probability of the outcome being positive. The threshold for determining a positive or negative outcome can vary depending on the problem. The derivative of the average loss is important in logistic regression because it allows us to find the optimal values for x and b by setting the gradient to zero.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:59:43.002954Z",
     "start_time": "2025-04-06T18:59:42.999761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_docs = answer['source_documents']\n",
    "print(\"Number of source documents: \" + str(len(source_docs)))\n",
    "\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f\"Source document {i}\")\n",
    "    print(f\"Page: {doc.metadata['page']}\")\n",
    "    print(f\"Content: {doc.page_content[:10]}\")\n",
    "    print(\"-----\")\n",
    "\n",
    "source_docs"
   ],
   "id": "1b81c7305e0d0eba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 2\n",
      "Source document 0\n",
      "Page: 32\n",
      "Content: 3.\n",
      "By look\n",
      "-----\n",
      "Source document 1\n",
      "Page: 31\n",
      "Content: y\n",
      "x\n",
      "new\n",
      "ne\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'creationdate': '2018-12-18T05:07:46+00:00', 'creator': 'PyPDF', 'moddate': '2019-01-22T19:51:34+00:00', 'page': 32, 'page_label': '33', 'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152}, page_content='3.\\nBy looking at the graph of the standard logistic function, we can see how well it ﬁts our\\nclassiﬁcation purpose: if we optimize the values ofx and b appropriately, we could interpret\\nthe output off(x) as the probability ofyi being positive. For example, if it’s higher than or\\nequal to the threshold0.5 we would say that the class ofx is positive; otherwise, it’s negative.\\nIn practice, the choice of the threshold could be di\\x00erent depending on the problem. We\\nreturn to this discussion in Chapter 5 when we talk about model performance assessment.\\nSo our logistic regression model looks like this:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'creationdate': '2018-12-18T05:07:46+00:00', 'creator': 'PyPDF', 'moddate': '2019-01-22T19:51:34+00:00', 'page': 31, 'page_label': '32', 'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152}, page_content='y\\nx\\nnew\\nnew\\nFigure 2: Overﬁtting.\\nmight also use the powers 3 or 4, but their derivatives are more complicated to work with.\\nFinally, why do we care about the derivative of the average loss? Remember from algebra\\nthat if we can calculate the gradient of the function in eq. 2, we can then set this gradient to\\nzero2 and ﬁnd the solution to a system of equations that gives us the optimal valueswú and\\nbú. You can spend several minutes and check it yourself.\\n3.2 Logistic Regression\\nThe ﬁrst thing to say is that logistic regression is not a regression, but a classiﬁcation learning\\nalgorithm. The name comes from statistics and is due to the fact that the mathematical\\nformulation of logistic regression is similar to that of linear regression.\\nI explain logistic regression on the case of binary classiﬁcation. However, it can naturally be\\nextended to multiclass classiﬁcation.\\n3.2.1 Problem Statement')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:51:39.964235Z",
     "start_time": "2025-04-06T18:51:39.961441Z"
    }
   },
   "cell_type": "code",
   "source": "source_docs[0]",
   "id": "2f25c529077909ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'creationdate': '2018-12-18T05:07:46+00:00', 'creator': 'PyPDF', 'moddate': '2019-01-22T19:51:34+00:00', 'page': 32, 'page_label': '33', 'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152}, page_content='3.\\nBy looking at the graph of the standard logistic function, we can see how well it ﬁts our\\nclassiﬁcation purpose: if we optimize the values ofx and b appropriately, we could interpret\\nthe output off(x) as the probability ofyi being positive. For example, if it’s higher than or\\nequal to the threshold0.5 we would say that the class ofx is positive; otherwise, it’s negative.\\nIn practice, the choice of the threshold could be di\\x00erent depending on the problem. We\\nreturn to this discussion in Chapter 5 when we talk about model performance assessment.\\nSo our logistic regression model looks like this:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:51:39.978345Z",
     "start_time": "2025-04-06T18:51:39.975671Z"
    }
   },
   "cell_type": "code",
   "source": "source_docs[1]",
   "id": "c93185f618c1a110",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'creationdate': '2018-12-18T05:07:46+00:00', 'creator': 'PyPDF', 'moddate': '2019-01-22T19:51:34+00:00', 'page': 31, 'page_label': '32', 'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152}, page_content='y\\nx\\nnew\\nnew\\nFigure 2: Overﬁtting.\\nmight also use the powers 3 or 4, but their derivatives are more complicated to work with.\\nFinally, why do we care about the derivative of the average loss? Remember from algebra\\nthat if we can calculate the gradient of the function in eq. 2, we can then set this gradient to\\nzero2 and ﬁnd the solution to a system of equations that gives us the optimal valueswú and\\nbú. You can spend several minutes and check it yourself.\\n3.2 Logistic Regression\\nThe ﬁrst thing to say is that logistic regression is not a regression, but a classiﬁcation learning\\nalgorithm. The name comes from statistics and is due to the fact that the mathematical\\nformulation of logistic regression is similar to that of linear regression.\\nI explain logistic regression on the case of binary classiﬁcation. However, it can naturally be\\nextended to multiclass classiﬁcation.\\n3.2.1 Problem Statement')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
