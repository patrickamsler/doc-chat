{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T04:47:18.563748Z",
     "start_time": "2025-04-16T04:47:18.559850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import secrets\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from doc_chat.rag.document_loader import DocumentLoader\n",
    "from doc_chat.rag.vector_store import VectorStore\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ],
   "id": "82d9bd9c8ff121ec",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:33.025414Z",
     "start_time": "2025-04-15T18:13:57.082399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"../data/pdf/The Hundred-Page Machine Learning Book.pdf\"\n",
    "doc_loader = DocumentLoader(file_path)\n",
    "documents, splits = doc_loader.load_and_split()\n",
    "print(\"Number of documents: \" + str(len(documents)))\n",
    "print(\"Number of splits: \" + str(len(splits)))"
   ],
   "id": "3ab4e21534ad9deb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 152\n",
      "Number of splits: 385\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:33.121450Z",
     "start_time": "2025-04-15T18:14:33.118121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# document format\n",
    "documents[0]"
   ],
   "id": "2a891db20f76d3b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152, 'page': 0, 'page_label': '1'}, page_content='The\\nHundred-\\nPage\\nMachine\\nLearning\\nBook\\nAndriy Burkov')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:33.128046Z",
     "start_time": "2025-04-15T18:14:33.125837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print first 300 characters of the third page\n",
    "documents[2].page_content[:300]"
   ],
   "id": "70fe79e5cf5a314c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preface\\nLet’s start by telling the truth: machines don’t learn. What a typical “learning machine”\\ndoes, is ﬁnding a mathematical formula, which, when applied to a collection of inputs (called\\n“training data”), produces the desired outputs. This mathematical formula also generates the\\ncorrect outputs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:33.141360Z",
     "start_time": "2025-04-15T18:14:33.139071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split format\n",
    "splits[0]"
   ],
   "id": "63125bc673e1b99d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152, 'page': 0, 'page_label': '1'}, page_content='The\\nHundred-\\nPage\\nMachine\\nLearning\\nBook\\nAndriy Burkov')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:33.150337Z",
     "start_time": "2025-04-15T18:14:33.147999Z"
    }
   },
   "cell_type": "code",
   "source": "splits[2].page_content",
   "id": "1b6bafe36143cc5f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preface\\nLet’s start by telling the truth: machines don’t learn. What a typical “learning machine”\\ndoes, is ﬁnding a mathematical formula, which, when applied to a collection of inputs (called\\n“training data”), produces the desired outputs. This mathematical formula also generates the\\ncorrect outputs for most other inputs (distinct from the training data) on the condition that\\nthose inputs come from the same or a similar statistical distribution as the one the training\\ndata was drawn from.\\nWhy isn’t that learning? Because if you slightly distort the inputs, the output is very likely\\nto become completely wrong. It’s not how learning in animals works. If you learned to play\\na video game by looking straight at the screen, you would still be a good player if someone\\nrotates the screen slightly. A machine learning algorithm, if it was trained by “looking”\\nstraight at the screen, unless it was also trained to recognize rotation, will fail to play the\\ngame on a rotated screen.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T04:47:38.077239Z",
     "start_time": "2025-04-16T04:47:34.489561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# instantiate vector store\n",
    "token = secrets.token_urlsafe(16)\n",
    "vector_store = VectorStore(documents=splits, token=token)"
   ],
   "id": "4c2e0a6938202300",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T04:47:43.752281Z",
     "start_time": "2025-04-16T04:47:40.705254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conversational_chain = vector_store.create_conversational_retrieval_chain(k=2)\n",
    "response = conversational_chain.invoke(\"Explain logistic regression\")\n",
    "print(response['answer'])"
   ],
   "id": "5588f00f3ead90f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression is a type of classification model that uses a continuous function called the standard logistic function (also known as the sigmoid function) to predict the probability of a certain outcome. This function maps input values to a range between 0 and 1, making it suitable for binary classification problems. By optimizing the values of the function's parameters, we can interpret the output as the probability of a positive outcome. The choice of threshold for determining positive or negative labels may vary depending on the problem. Logistic regression was developed as a simple linear classification model before the advent of computers, and it remains a popular and useful tool in machine learning.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T04:47:45.501703Z",
     "start_time": "2025-04-16T04:47:45.498001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_docs = response['source_documents']\n",
    "print(\"Number of source documents: \" + str(len(source_docs)))\n",
    "\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f\"Source document {i}\")\n",
    "    print(f\"Page: {doc.metadata['page']}\")\n",
    "    print(f\"Content: {doc.page_content[:10]}\")\n",
    "    print(\"-----\")\n",
    "\n",
    "source_docs"
   ],
   "id": "1b81c7305e0d0eba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 2\n",
      "Source document 0\n",
      "Page: 32\n",
      "Content: 3.\n",
      "By look\n",
      "-----\n",
      "Source document 1\n",
      "Page: 32\n",
      "Content: Figure 3: \n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'creationdate': '2018-12-18T05:07:46+00:00', 'creator': 'PyPDF', 'moddate': '2019-01-22T19:51:34+00:00', 'page': 32, 'page_label': '33', 'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152}, page_content='3.\\nBy looking at the graph of the standard logistic function, we can see how well it ﬁts our\\nclassiﬁcation purpose: if we optimize the values ofx and b appropriately, we could interpret\\nthe output off(x) as the probability ofyi being positive. For example, if it’s higher than or\\nequal to the threshold0.5 we would say that the class ofx is positive; otherwise, it’s negative.\\nIn practice, the choice of the threshold could be di\\x00erent depending on the problem. We\\nreturn to this discussion in Chapter 5 when we talk about model performance assessment.\\nSo our logistic regression model looks like this:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'creationdate': '2018-12-18T05:07:46+00:00', 'creator': 'PyPDF', 'moddate': '2019-01-22T19:51:34+00:00', 'page': 32, 'page_label': '33', 'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152}, page_content='Figure 3: Standard logistic function.\\nAt the time where the absence of computers required scientists to perform manual calculations,\\nthey were eager to ﬁnd a linear classiﬁcation model. They ﬁgured out that if we deﬁne a\\nnegative label as0 and the positive label as1, we would just need to ﬁnd a simple continuous\\nfunction whose codomain is(0, 1). In such a case, if the value returned by the model for\\ninput x is closer to0, then we assign a negative label tox; otherwise, the example is labeled\\nas positive. One function that has such a property is thestandard logistic function(also\\nknown as thesigmoid function):\\nf(x)= 1\\n1+ e≠x ,\\nwhere e is the base of the natural logarithm (also calledEuler’s number; ex is also known as\\nthe exp(x) function in Excel and many programming languages). Its graph is depicted in ﬁg.\\n3.\\nBy looking at the graph of the standard logistic function, we can see how well it ﬁts our')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:40.997625Z",
     "start_time": "2025-04-15T18:14:40.994981Z"
    }
   },
   "cell_type": "code",
   "source": "source_docs[0]",
   "id": "2f25c529077909ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'creationdate': '2018-12-18T05:07:46+00:00', 'creator': 'PyPDF', 'moddate': '2019-01-22T19:51:34+00:00', 'page': 32, 'page_label': '33', 'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152}, page_content='3.\\nBy looking at the graph of the standard logistic function, we can see how well it ﬁts our\\nclassiﬁcation purpose: if we optimize the values ofx and b appropriately, we could interpret\\nthe output off(x) as the probability ofyi being positive. For example, if it’s higher than or\\nequal to the threshold0.5 we would say that the class ofx is positive; otherwise, it’s negative.\\nIn practice, the choice of the threshold could be di\\x00erent depending on the problem. We\\nreturn to this discussion in Chapter 5 when we talk about model performance assessment.\\nSo our logistic regression model looks like this:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:41.018003Z",
     "start_time": "2025-04-15T18:14:41.015724Z"
    }
   },
   "cell_type": "code",
   "source": "source_docs[1]",
   "id": "c93185f618c1a110",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'creationdate': '2018-12-18T05:07:46+00:00', 'creator': 'PyPDF', 'moddate': '2019-01-22T19:51:34+00:00', 'page': 32, 'page_label': '33', 'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'source': '../data/pdf/The Hundred-Page Machine Learning Book.pdf', 'total_pages': 152}, page_content='3.\\nBy looking at the graph of the standard logistic function, we can see how well it ﬁts our\\nclassiﬁcation purpose: if we optimize the values ofx and b appropriately, we could interpret\\nthe output off(x) as the probability ofyi being positive. For example, if it’s higher than or\\nequal to the threshold0.5 we would say that the class ofx is positive; otherwise, it’s negative.\\nIn practice, the choice of the threshold could be di\\x00erent depending on the problem. We\\nreturn to this discussion in Chapter 5 when we talk about model performance assessment.\\nSo our logistic regression model looks like this:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:43.854542Z",
     "start_time": "2025-04-15T18:14:41.023995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# conversational_chain can be used to ask follow-up questions\n",
    "response = conversational_chain.invoke(\"Give me the formula\")\n",
    "print(response['answer'])"
   ],
   "id": "529a135a91ed324",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The formula for logistic regression is f(x) = 1 / (1 + e^(-x)).\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:46.370889Z",
     "start_time": "2025-04-15T18:14:43.871161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# qa chain does not use the history of the conversation\n",
    "qa_chain = vector_store.create_qa_chain(k=2)\n",
    "response = qa_chain.invoke(\"Explain logistic regression\")\n",
    "print(response['result'])"
   ],
   "id": "d35c49dea220a6a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression is a type of classification algorithm that uses the standard logistic function to model the relationship between a set of input variables and a binary output variable. By optimizing the values of the input variables and a bias term, the output of the logistic function can be interpreted as the probability of the output variable being positive. A threshold can then be chosen to classify the output as either positive or negative. This threshold may vary depending on the problem at hand. Logistic regression is often used in machine learning for binary classification tasks.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:14:47.589746Z",
     "start_time": "2025-04-15T18:14:46.436844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# a follow-up question to the qa does not result in answer\n",
    "response = qa_chain.invoke(\"Give me the formula\")\n",
    "print(response['result'])"
   ],
   "id": "249162febb8045e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I don't know.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T04:53:44.424932Z",
     "start_time": "2025-04-16T04:53:43.736038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# retrieve only documents without call to the LLM\n",
    "documents = vector_store.retrieve_documents(\"Explain logistic regression\", k=2)\n",
    "\n",
    "for doc in documents:\n",
    "    print(f\"Page: {doc.metadata['page']}\")\n",
    "    print(f\"Content: {doc.page_content[:300]}\")"
   ],
   "id": "2167476827c4fdee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 32\n",
      "Content: 3.\n",
      "By looking at the graph of the standard logistic function, we can see how well it ﬁts our\n",
      "classiﬁcation purpose: if we optimize the values ofx and b appropriately, we could interpret\n",
      "the output off(x) as the probability ofyi being positive. For example, if it’s higher than or\n",
      "equal to the thresho\n",
      "Page: 32\n",
      "Content: Figure 3: Standard logistic function.\n",
      "At the time where the absence of computers required scientists to perform manual calculations,\n",
      "they were eager to ﬁnd a linear classiﬁcation model. They ﬁgured out that if we deﬁne a\n",
      "negative label as0 and the positive label as1, we would just need to ﬁnd a simp\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
